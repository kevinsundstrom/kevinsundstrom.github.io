# Agent Improvements Folder

This folder contains learning analysis reports and agent configuration recommendations generated by the Learning Agent.

## Purpose

The Learning Agent analyzes human edits to agent outputs and stores its findings here:
- Analysis reports of edit patterns
- Recommendations for agent improvements
- Pattern databases tracking consistency
- Historical improvement tracking

## Contents

### Analysis Reports

**Format**: `{agent-name}-analysis-{date}.md`

Example: `drafter-analysis-20260213.md`

Contains:
- Detailed comparison of original vs edited content
- Classification of change types
- Pattern matching against historical data
- Consistency analysis
- Recommendations (if patterns are consistent)

### Recommendation Files

**Format**: `{agent-name}-recommendations-{date}.md`

Example: `drafter-recommendations-20260213.md`

Contains:
- Specific agent config changes to make
- Rationale for each recommendation
- Evidence of pattern consistency
- Implementation instructions
- Expected impact

### Pattern Databases

**Format**: `edit-patterns-{agent-name}.json`

Example: `edit-patterns-drafter.json`

Contains:
- Cumulative record of all edit patterns
- Occurrence counts
- Editor information
- Pattern status (new/monitoring/recommended/implemented)
- Historical trends

## How the Learning System Works

```
1. Human edits agent output
   ↓
2. Both versions stored in edits/ folder
   ↓
3. Learning Agent analyzes differences
   ↓
4. Patterns identified and tracked
   ↓
5. Analysis report created here (improvements/)
   ↓
6. If pattern is consistent (3+ occurrences):
   → Recommendation file created
   ↓
7. Human reviews recommendation
   ↓
8. If approved, agent config updated
   ↓
9. Pattern marked as "implemented"
   ↓
10. System produces better outputs
```

## Recommendation Lifecycle

### 1. Pattern Detection
- Edit happens
- Learning Agent analyzes
- Pattern recorded in database
- Status: **"monitoring"**

### 2. Recommendation Generated
- Pattern reaches threshold (3-5 occurrences)
- Recommendation file created
- Status: **"pending-review"**

### 3. Human Review
- Team reviews recommendation
- Discussion happens
- Decision made
- Status: **"approved"** or **"rejected"**

### 4. Implementation
- Approved changes made to agent config
- Agent version incremented
- Status: **"implemented"**

### 5. Validation
- New outputs tested
- Pattern should decrease
- Status: **"validated"** or **"needs-revision"**

## File Examples

### Analysis Report Structure

```markdown
# Learning Analysis Report

**Agent**: Drafter
**Comparison**: draft-original vs draft-edited
**Editor**: Jane Smith

## Edit Summary
- Structural changes: 2
- Clarity changes: 5
- Style changes: 3

## Detailed Analysis
[Each change analyzed...]

## Pattern Detection
- Pattern #7: Complex sentences broken up (5th occurrence)
  Status: Ready for recommendation

## Recommendations
- Update drafter instructions to limit sentence length
```

### Recommendation File Structure

```markdown
# Agent Improvement Recommendations

**Agent**: Drafter
**Date**: 2026-02-13
**Confidence**: High

## Recommendation 1: Limit Sentence Length

**Pattern**: Complex sentences consistently broken into shorter ones
**Occurrences**: 5 instances across 3 pieces
**Editors**: Jane, John, Mary

**Current Config Problem**:
No guidance on sentence length

**Proposed Change**:
Add to drafter.agent.md constraints section:
"Keep sentences under 25 words for clarity. Break complex ideas into multiple sentences."

**Expected Impact**:
- Reduce editing time by 15%
- Improve readability
- Fewer clarity issues

**Implementation**:
File: content-workflow/drafter.agent.md
Section: constraints
Line: Add after "Focus on first draft quality"
```

## Pattern Database Structure

```json
{
  "agent": "drafter",
  "last_updated": "2026-02-13",
  "total_analyses": 12,
  "patterns": [
    {
      "id": "draft-001",
      "type": "clarity",
      "description": "Complex sentences broken into simpler ones",
      "occurrences": 5,
      "first_seen": "2026-01-15",
      "last_seen": "2026-02-13",
      "editors": ["jane", "john", "mary"],
      "consistency_score": 0.83,
      "status": "pending-review",
      "recommendation_id": "rec-draft-001"
    }
  ],
  "recommendations": [
    {
      "id": "rec-draft-001",
      "date": "2026-02-13",
      "patterns": ["draft-001", "draft-003"],
      "config_change": "Add sentence length constraint",
      "status": "pending-review",
      "priority": "high"
    }
  ],
  "implemented_improvements": [
    {
      "id": "impl-001",
      "date": "2026-02-01",
      "change": "Added example requirement",
      "result": "90% reduction in 'needs examples' edits"
    }
  ]
}
```

## Reviewing Recommendations

### Process

1. **Notification**
   - New recommendations appear in this folder
   - GitHub issue created (if workflow configured)
   - Team notified

2. **Review Meeting**
   - Review recommendations together
   - Discuss evidence and rationale
   - Consider implications
   - Make decision

3. **Decision Documentation**
   - Approve: Update recommendation status to "approved"
   - Reject: Update status to "rejected" with reason
   - Defer: Update status to "monitoring" for more data

4. **Implementation**
   - For approved recommendations:
   - Update agent configuration
   - Test changes
   - Monitor results

### Review Checklist

- [ ] Pattern is genuinely consistent (not one-off)
- [ ] Sample size is sufficient (3-5+ instances)
- [ ] Change aligns with agent purpose
- [ ] Change is teachable via configuration
- [ ] No conflicts with other agents or guidelines
- [ ] Expected improvement is clear
- [ ] Implementation is straightforward

## Monitoring Improvement Impact

After implementing changes:

1. **Track Pattern Occurrence**
   - Should decrease if fix is working
   - Pattern database shows trends

2. **Measure Edit Rate**
   - Compare editing time before/after
   - Track types of edits still needed

3. **Quality Assessment**
   - Does output quality improve?
   - Are new issues introduced?
   - Overall impact on workflow

4. **Iterate**
   - Adjust if needed
   - Continue monitoring
   - Refine further based on results

## Best Practices

### For Pattern Detection
- ✓ Need 3-5 occurrences for confidence
- ✓ Prefer multiple editors confirming
- ✓ Look for teachable patterns
- ✗ Don't overreact to single edits
- ✗ Don't implement contradictory changes

### For Recommendations
- ✓ Be specific and actionable
- ✓ Explain rationale clearly
- ✓ Provide examples
- ✓ Estimate impact
- ✗ Don't recommend vague changes
- ✗ Don't change agent purpose

### For Implementation
- ✓ Test changes before deploying
- ✓ Update one agent at a time
- ✓ Monitor results
- ✓ Be ready to revert if needed
- ✗ Don't make multiple changes at once
- ✗ Don't skip testing

## Continuous Improvement Metrics

Track over time:
- **Edit Rate**: Changes per agent output (target: decrease)
- **Pattern Consistency**: How often patterns repeat (target: identify high-confidence patterns)
- **Implementation Rate**: Approved recommendations implemented (target: >80%)
- **Impact**: Measured improvement after changes (target: 10-20% reduction in edit time)
- **Quality**: Output quality scores (target: increase)

## Access and Permissions

- **Read**: All team members
- **Analyze**: Learning Agent (automated)
- **Review**: Editorial team, administrators
- **Implement**: Administrators only

## Questions?

- **How often does learning analysis run?** After each human edit submission
- **Who approves recommendations?** Editorial team and administrators
- **How long until I see improvements?** 1-2 weeks after implementation
- **What if a recommendation doesn't work?** Revert and mark for revision
- **Can I request analysis of specific patterns?** Yes, open an issue

---

**This folder enables continuous improvement. The system learns from experience and gets better over time.**
